# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'new.ui'
#
# Created by: PyQt5 UI code generator 5.15.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.
import sys
import cv2
import time
from os import getcwd
from PyQt5.QtCore import Qt
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QFileDialog
import numpy as np
from real_time_video_me import Emotion_Rec
#import speech_recog as sp

class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName("Form")
        Form.resize(800, 800)
        self.label = QtWidgets.QLabel(Form)
        self.label.setGeometry(QtCore.QRect(110, 20, 281, 20))
        self.label.setObjectName("label")
        self.pushButton = QtWidgets.QPushButton(Form)
        self.pushButton.setGeometry(QtCore.QRect(50, 60, 93, 28))
        self.pushButton.setObjectName("pushButton")
        self.pushButton_2 = QtWidgets.QPushButton(Form)
        self.pushButton_2.setGeometry(QtCore.QRect(320, 60, 93, 28))
        self.pushButton_2.setObjectName("pushButton_2")
        self.label_2 = QtWidgets.QLabel(Form)
        self.label_2.setGeometry(QtCore.QRect(50, 110, 381, 201))
        self.label_2.setObjectName("label_2")
        self.label_3 = QtWidgets.QLabel(Form)
        self.label_3.setGeometry(QtCore.QRect(50, 330, 381, 201))
        self.label_3.setObjectName("label_3")
        self.label_time = QtWidgets.QLabel(Form)
        self.label_time.setGeometry(QtCore.QRect(150, 560, 61, 21))
        self.label_time.setObjectName("label_time")
        self.label_4 = QtWidgets.QLabel(Form)
        self.label_4.setGeometry(QtCore.QRect(50, 560, 61, 21))
        self.label_4.setObjectName("label_4")
        self.label_result = QtWidgets.QLabel(Form)
        self.label_result.setGeometry(QtCore.QRect(390, 560, 41, 21))
        self.label_result.setObjectName("label_result")
        self.label_5 = QtWidgets.QLabel(Form)
        self.label_5.setGeometry(QtCore.QRect(290, 560, 81, 21))
        self.label_5.setObjectName("label_5")

        self.retranslateUi(Form)
        self.centralwidget = QtWidgets.QWidget(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)
        self.model_path = "models//_mini_XCEPTION.102-0.66.hdf5"  # model path
        self.timer_camera = QtCore.QTimer()  # counter
        self.cap = cv2.VideoCapture() # get camera
        self.CAM_NUM = 0 # number of camera
        self.slot_init() 

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate("Form", "Deep learning based expression recognition system"))
        self.label.setText(_translate("Form", "<html><head/><body><p><span style=\" font-size:12pt; font-weight:600;\">Deep learning based expression recognition system</span></p></body></html>"))
        self.pushButton.setText(_translate("Form", "Select image"))
        self.pushButton_2.setText(_translate("Form", "Turn on the camera"))
        self.label_2.setText(_translate("Form", "                  Show picture"))
        self.label_3.setText(_translate("Form", "                  Show Probability"))
        self.label_time.setText(_translate("Form", "0 s"))
        self.label_4.setText(_translate("Form", "Recognition time："))
        self.label_result.setText(_translate("Form", "None"))
        self.label_5.setText(_translate("Form", "Identification results："))


    def slot_init(self): #Define the slot function
        self.pushButton_2.clicked.connect(self.button_open_camera_click)
        self.pushButton.clicked.connect(self.choose_pic)
        self.timer_camera.timeout.connect(self.show_camera)

    def cv_imread(self,filePath):

        cv_img=cv2.imdecode(np.fromfile(filePath,dtype=np.uint8),-1)
        ## imdecode reads rgb, if the subsequent need for opencv processing, you need to convert to bgr, the conversion of the image color will change
        ## cv_img=cv2.cvtColor(cv_img,cv2.COLOR_RGB2BGR)
        return cv_img

    def choose_pic(self):
        # Use the file selection dialog to select a picture
        fileName_choose, filetype = QFileDialog.getOpenFileName(
                                self.centralwidget, "choose img",
                                getcwd(),  # init path
                                "img(*.jpg;*.jpeg;*.png)") # file type
        self.path = fileName_choose # save path
        self.timer_camera.stop() # Turn off the timer started by the camera
        # Show prompt message
        if fileName_choose != '':
            self.emotion_model = Emotion_Rec(self.model_path)
            image = self.cv_imread(fileName_choose) # Read the selected image
            canvas = cv2.imread('slice.jpg')  # Background image for data display
            canvas = cv2.resize(canvas, (380, 200))
            # Timing and start model prediction
            QtWidgets.QApplication.processEvents()
            time_start = time.time()
            result = self.emotion_model.run(image, canvas, self.label_2, self.label_3)
            time_end = time.time()
            # Show results
            self.label_result.setText(result)
            self.label_time.setText(str(round((time_end - time_start), 3)) + ' s')
        else:
            self.label_2.setText('Image not selected')

        QtWidgets.QApplication.processEvents()

    def button_open_camera_click(self):
        if self.timer_camera.isActive() == False: #Check timing status
            flag = self.cap.open(self.CAM_NUM) # Check camera status
            if flag == False:
                msg = QtWidgets.QMessageBox.warning(self.centralwidget, u"Warning",
                                                    u"Please check if the camera and computer are connected correctly！ ",
                                                    buttons=QtWidgets.QMessageBox.Ok,
                                                    defaultButton=QtWidgets.QMessageBox.Ok)
            else:
                self.label_2.setText('Identification system being activated...\n\nleading')
                self.emotion_model = Emotion_Rec(self.model_path)
             
                self.timer_camera.start(30)

    def show_camera(self):
        # Timer slot function, executed at regular intervals
        flag, self.image = self.cap.read() # Get Screen
        self.image=cv2.flip(self.image, 1) # Left and right flip
        canvas = cv2.imread('slice.jpg')  # Background image for data display
        canvas = cv2.resize(canvas, (380, 200))
        time_start = time.time() # 计时
        # Prediction using models
        result = self.emotion_model.run(self.image, canvas, self.label_2, self.label_3)
        time_end = time.time()
        # Show results in the interface
        self.label_result.setText(result)
        self.label_time.setText(str(round((time_end-time_start),3))+' s')

if  __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)

    baseWidget = QtWidgets.QWidget()  # Create an instance of QWidget, the base class for windows

    ui = Ui_Form()  # Example of creating a UI window
    ui.setupUi(baseWidget)  # Using baseWidget as a passing parameter

    baseWidget.show()
    ##ui.LabHello.setText("Hello,modified by the program") # can modify the text of the label on the form
    #Calling speech recognition
    #sp.bar_chart()
    #Calling audio recognition
    #sp.predict_audio()
    sys.exit(app.exec_())
